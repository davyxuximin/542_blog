{
  "hash": "f62cb4e01ecd649b5a9051daa4ee6466",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A First Touch to Machine Learning: A Generalized Classification Tutorial\"\nauthor: \"Ximin Xu\"\ndate: \"2025-01-17\"\ncategories: [code, analysis, tutorial]\nbibliography: references.bib\n---\n\n![Picture of a robot thinking on math question, picture created by [@Joshinav_2023]](./images/ml.jpg){#fig-machinelearning width=100%}\n\nImagine a world where your smartphone predicts your next word as you type, where cars drive themselves, and where medical diagnoses are enhanced by machines detecting anomalies invisible to the human eye. These aren't the works of science fiction—they’re the real-life applications of machine learning.\n\nMachine learning is a transformative field where computers learn patterns from data, enabling them to make predictions, solve problems, and even adapt to new challenges without being explicitly programmed. It's the invisible engine powering innovations in healthcare, finance, entertainment, and virtually every industry you can think of.\n\nIn this tutorial, I will be teaching how to create a classification model (a model that is used to classified an item) using sci-kit learn package. A detail of the example used can be found in the repository [here](https://github.com/UBC-MDS/Car_Evaluation_Analysis)\n\n## Prerequisite:\nBefore proceed to this tutorial, make sure you have these installed in your computer:\n\n- An IDE, e.g. (Visual Studio Code)[https://code.visualstudio.com]\n- [Python 3.7+](https://www.python.org/downloads/)[@Python]\n- [conda](https://docs.conda.io/projects/conda/en/stable/user-guide/getting-started.html) (recommended)[@anaconda]\n- [Pandas](https://pandas.pydata.org/docs/getting_started/install.html)[@mckinney-proc-scipy-2010]\n- [Scikit-learn](https://scikit-learn.org/stable/install.html)[@scikit-learn]\n\nConda is recommended because it is a powerful package and environment management tool. The packages listed above need to be installed in your environment before proceed, you can test by typing the following in your terminal:\n\n```{bash}\n#| label: dependencies_check\npython --version\n#Python 3.11.9\n\nconda list pandas\n# packages in environment at /Users/yourname/miniforge3:\n#\n# Name                    Version                   Build  Channel\n#pandas                    2.1.4                    pypi_0    pypi\n\nconda list scikit-learn\n# packages in environment at /Users/yourname/miniforge3:\n#\n# Name                    Version                   Build  Channel\n#scikit-learn              1.3.2                    pypi_0    pypi\n```\n\n\n## Introduction to the dataset\nImagine you want to buy a car, but you don't know if the car is worth to buy or not. Before taking out your wallet and writing a cheque, you want to analyze the value for money of the car. From the appearance of it, you can see some attributes, including the number of doors, seating compacity and boot size. Besides, financial cost including buying price and maintenance cost are also important when considering the cost performance. After gathering these information, you hope there exists a robot telling you the car is acceptable or not. The robot you hope is the model we are going to train later this tutorial.\n\n![Picture of a woman purchases a car, picture created by [@McIntosh_2022]](./images/buying-car-at-dealership-gettyimages-1342043587-peopleimages.jpg){#fig-buyingcar width=100%}\n\n\nThe dataset[@dataset] we are going to use contains a large number of these information. You can find the data in [here](https://archive.ics.uci.edu/dataset/19/car+evaluation). This is a data from UCI machine Learning Repository. You need to download it to your local before continue this tutorial, you can also find it in the repo. I recommed to download it at the `data/` of the root of your project.\n\n## Load the data\nThis first thing to do is to load the dataset, open your IDE, create a new python file. We can name it as `car_eva.py`. Import packages and modules needed for the project as following:\n\n::: {#import .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\n```\n:::\n\n\nNext, we will need to import our data, you can do it by the following:\n\n::: {#load_data .cell execution_count=2}\n``` {.python .cell-code}\ncolnames = ['buying','maint','doors','persons','lug_boot','safety','class']\nraw_data = pd.read_csv(\"./data/car_data_raw.csv\", names=colnames, header = 1)\n```\n:::\n\n\nThe whole python document will look something like this:\n\n::: {#pyfile .cell execution_count=3}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\ndef main():\n    colnames = ['buying','maint','doors','persons','lug_boot','safety','class']\n    raw_data = pd.read_csv(\"./data/car_data_raw.csv\", names=colnames, header = 1)\n    \nif __name__ == '__main__':\n    main()\n```\n:::\n\n\nFor following steps, you will need to update the `main()` function. To execute the file, simply type `python path-to-py-file` to your terminal.\n\n## Quick inspection of the data and do analysis on it\nThe next thing needed to do is do a inspection to the nature of the data. Because we want to create a classification model, we shall make sure that the target we are predicting is a classification data, then we need to see the data type of the attributes:\n\n::: {#print .cell execution_count=4}\n``` {.python .cell-code}\nprint(raw_data.head())\nprint(raw_data.info())\n```\n:::\n\n\nAs we can see, the dataset have all object datatype, and the target we want to predict is the `class` of the car. The car attributes is as follow:\n\n-   Buying price: `low`, `med`, `high`, `vhigh`\n-   Maintenance cost: `low`, `med`, `high`, `vhigh`\n-   Number of doors: `2`, `3`, `4`, `5more`\n-   Seating capacity: `2`, `4`, `more`\n-   Boot size: `small`, `med`, `big`\n-   Safety rating: `low`, `med`, `high`\n\nThe class column includes the following value:\n\n- `unacc`: Unacceptable. Cars that fail to meet basic criteria.\n- `acc`: Acceptable. Cars that meet minimum requirements.\n- `good`: Good. Cars that exceed average standards in some aspects.\n- `vgood`: Very good. Cars that meet the highest standards.\n\nIn machine learning, the features are usually denoted as `X`, and the target is denoted as `y`, we can do as following:\n\n::: {#x_y_split .cell execution_count=5}\n``` {.python .cell-code}\nX = raw_data.drop(\"class\", axis=1)\ny = raw_data[\"class\"]\n```\n:::\n\n\nCan we start training the model using this data? No!\nWhy? Because if we train the model using all the data here, we will have no data to test it. The golden rule of the machine learning indicates that we shall never use test data to train the model. Therefore, we need to split the data into train set and test set. Luckily, `sci-kit learn` has a module to split them in one line:\n\n::: {#train_test_split .cell execution_count=6}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=522\n)\n```\n:::\n\n\nBy doing so, we split the data by 20% test and 80% train.\nBefore heading to train the model, the `sci-kit learn` model will only accept numeric columns to train. We need to transform our categorical columns to numeric before fitting the model. Here, since all columns are ordinal(low, med, high etc.). We can use a sklearn encoder called `OrdinalEncoder`. This encoder can transform ordinal categorical column value like 'low' 'medium' 'high' to 0, 1, 2:\n\n::: {#preprocessor .cell execution_count=7}\n``` {.python .cell-code}\ncar_preprocessor = make_column_transformer(\n        (OrdinalEncoder(categories=[['low','med','high','vhigh']]), ['buying']),\n        (OrdinalEncoder(categories=[['low','med','high','vhigh']]), ['maint']),\n        (OrdinalEncoder(categories=[['2','3','4','5more']]), ['doors']),\n        (OrdinalEncoder(categories=[['2','4','more']]), ['persons']),\n        (OrdinalEncoder(categories=[['small','med','big']]), ['lug_boot']),\n        (OrdinalEncoder(categories=[['low','med','high']]), ['safety']),\n        remainder='passthrough',\n        verbose_feature_names_out=False\n    )\n```\n:::\n\n\nBy doing this, we encode the columns to numeric, which is now good for our model to fit.\n\n## Model training\nFor this example, we are going to use a model called SVC with RBF kernel. You can think of\nSVM as a tool that draws lines in a way that best separates different categories—in this case, car acceptability levels. As we get deeper into machine learning, we will need to tune the hyperparameter of the model. This process is like looking for a way to adjust car components to make it drive the fastest. Instead of car components, we adjust the hyperparameter of the model. Since this is a beginner tutorial, I will provide a good hyperparameter C is equal to 100 and gamma is equal to 0.1 to this model here.\n\n::: {#fit_model .cell execution_count=8}\n``` {.python .cell-code}\nsvc = SVC(C = 1000, gamma = 0.01, random_state=522)\ncar_pipe = make_pipeline(car_preprocessor, svc)\ncar_pipe.fit(X_train, y_train)\n```\n:::\n\n\nThere are other models in `sklearn` package like Random Forest classifier or KNN classifier. For more models you can check the scikit learn documentation [here](https://scikit-learn.org/1.5/supervised_learning.html).\n\n## Test our model\nNow we have trained our model using the training data, how are we suppose to test the performance of our trained model?\nWell, remember the test data we splited out earlier this tutorial? Now it's the time to use it. We can give the features from the test data to our model and let it predict the outcome, and calculate the accuracy of the model. We can use the `.score()` function of `sklearn` to do this:\n\n::: {#score .cell execution_count=9}\n``` {.python .cell-code}\nscore = car_pipe.score(X_test, y_test).round(3)\nprint(f\"The accuracy of our mode is {score}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe accuracy of our mode is 0.965\n```\n:::\n:::\n\n\nBesides accuracy, we can create a classification report using `sklearn` module:\n\n::: {#classification_report .cell execution_count=10}\n``` {.python .cell-code}\npredictions = car_pipe.predict(X_test)\nprint(classification_report(y_test, predictions))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n         acc       0.88      0.97      0.93        76\n        good       0.92      0.80      0.86        15\n       unacc       1.00      0.98      0.99       240\n       vgood       1.00      0.87      0.93        15\n\n    accuracy                           0.97       346\n   macro avg       0.95      0.90      0.92       346\nweighted avg       0.97      0.97      0.97       346\n\n```\n:::\n:::\n\n\nThe precision here means how many predictions are correct and recall means how many relevant items are identified. F1 score gives a balance between the 2 metrics. Given the high score and accuracy here, we can say that the model we built is powerful and reliable.\nWe can also see a detail here, how many cars we are doing correct and how many we are doing incorrect, just use a confusion matrix[@fig-confusionmatrix]:\n\n::: {#confusion_matrix .cell execution_count=11}\n``` {.python .cell-code}\ncm = ConfusionMatrixDisplay.from_estimator(\n    car_pipe,\n    X_test,\n    y_test,\n    values_format=\"d\", \n)\n```\n:::\n\n\n![Confusion matrix visualizing the performance of the SVC RBF model, displaying the true positives, true negatives, false positives, and false negatives in a tabular format to assess classification accuracy and error rates.](./images/cm.png){#fig-confusionmatrix width=70%}\n\nNow, let's try to predict using our model:\n\n::: {#predict .cell execution_count=12}\n``` {.python .cell-code}\n#Create 2 car with one obviously good and one obviously bad\npredict_data = pd.DataFrame({\n    'buying': ['low', 'high'],\n    'maint': ['med', 'vhigh'],\n    'doors': ['4', '2'],\n    'persons': ['4', '2'],\n    'lug_boot': ['big', 'small'],\n    'safety': ['high', 'low']\n})\npredictions = car_pipe.predict(predict_data)\nprint(\"Predictions for the new data:\")\nfor i, prediction in enumerate(predictions):\n    print(f\"Sample {i+1}: {prediction}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredictions for the new data:\nSample 1: vgood\nSample 2: unacc\n```\n:::\n:::\n\n\nThe result is good and accurate!\n\n## Conclusion\nIn this blog, we demonstrated an end-to-end classification pipeline:\n\n1. Loaded and explored the Car Evaluation dataset.\n2. Transformed categorical features and split data for training/testing.\n3. Trained SVC model with RBF kernal.\n4. Evaluated them using accuracy, classification reports, and confusion matrices.\n\nThis is a shorter way of training a well-functional model. In real life you may need to tune the model, and do feature engineer in order to get a robust model.\n\nThis framework can be used for any classification task:\n- Swap in your own dataset.\n- Adjust the preprocessing steps.\n- Select and tune models based on your domain needs.\nWith these building blocks, you’re well on your way to solving practical ML classification challenges—whether you’re predicting car quality, diagnosing diseases, or detecting fraudulent transactions.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}